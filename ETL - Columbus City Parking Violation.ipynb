{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL - Columbus City Parking Violations and Ticket Status 2013-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate your python environment\n",
    "\n",
    "# Make sure to install this before running:\n",
    "# pip install pandas\n",
    "# pip install sqlalchemy\n",
    "# pip install psycopg2\n",
    "# pip install datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 1 of 3 CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discovery.smartcolumbusos.com/dataset/conduent/160c98a1_ad56_4658_8553_5ee8e7d0d953\n",
    "# Download this file from google drive link in readme as this is a big file\n",
    "data_csv = \"Parking_data.csv\"\n",
    "data_df = pd.read_csv(data_csv)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 2 of 3 CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://opendata.columbus.gov/datasets/parking-meters/data\n",
    "meters_csv = \"Parking_Meters.csv\"\n",
    "meters_df = pd.read_csv(meters_csv)\n",
    "meters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 3 of 3 CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metadata file to decode the column names\n",
    "#https://data.world/smartcolumbusos/040b5929-db26-4453-920a-ceb282c4359f/workspace/file?filename=geocoded-parking-violations-csv-5.csv\n",
    "columns_csv = \"metadata.csv\"\n",
    "columns_df = pd.read_csv(columns_csv, header=0, encoding = 'unicode_escape')\n",
    "columns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename viol to violation code - was getting a KeyError: \"['viol'] not in index\" in the next step\n",
    "data_df = data_df.rename(columns={\"viol\": \"violation_code\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns from both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select required columns from parking_data\n",
    "data_df = data_df[['ticket','iss dt','fine','violation_code','entity','make','iss time','lat','long','hold ct','badge','pay amt','location','meter']]\n",
    "\n",
    "# Rename columns \n",
    "data_df = data_df.rename(columns={\"ticket\": \"ticket_id\",\n",
    "                                \"iss dt\": \"issue_date\", \n",
    "                                  \"fine\": \"fine\",\n",
    "                                 \"violation_code\": \"violation_code\", \n",
    "                                  \"entity\": \"entity\",\n",
    "                                 \"make\": \"car_make\", \n",
    "                                  \"iss time\": \"issue_time\",\n",
    "                                 \"lat\": \"latitude\", \n",
    "                                  \"long\": \"longitude\",\n",
    "                                 \"hold ct\": \"total_tickets\", \n",
    "                                  \"badge\": \"officer_badge\",\n",
    "                                 \"pay amt\": \"amount_paid\",\n",
    "                                 \"location\": \"location\",\n",
    "                                 \"meter\": \"meter_id\"})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select required columns from parking_meter\n",
    "# Rename columns - easier to merge later\n",
    "meters_df = meters_df.rename(columns={\"METER_ID\": \"meter_id\",\"METER_STATUS\": \"meter_status\",\"RATE\": \"rate\" })\n",
    "meters_df.drop(meters_df.columns[[0,1,2,4,5,6,8,9,10,11,12,13,15,16,17,18]], axis = 1, inplace = True) \n",
    "meters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames (data_df and meters_df) together based on the Meter Ids they share\n",
    "merge_df = pd.merge(data_df, meters_df, on= \"meter_id\")\n",
    "merge_df.dropna(subset=['meter_id'])\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the merge data further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Drop latitude/longitude columns with values of 0\n",
    " - Add decimal points to both latitude and longitude\n",
    " - Set the the values in longitude column to all negative.\n",
    " - Convert Julian dates to normal dates in a dataframe and delete the old index\n",
    " - For loop to convert the military time into regular time and save it into list\n",
    " - Convert object to float\n",
    " - Reset index and delete old index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop latitude/longitude columns with values of 0:\n",
    "merge_df.drop(merge_df.index[merge_df['latitude'] == 0], inplace = True)\n",
    "merge_df.drop(merge_df.index[merge_df['longitude'] == 0], inplace = True)\n",
    "\n",
    "# Add decimal points to both latitude and longitude\n",
    "merge_df['latitude'] = merge_df['latitude'].apply(lambda x: x / 10 ** (len((str(x))) - 2))\n",
    "merge_df['longitude'] = merge_df['longitude'].apply(lambda x: x / 10 ** (len((str(x))) - 2))\n",
    "\n",
    "# Set the longitude column to be all negative. \n",
    "merge_df.longitude = merge_df.longitude*(-1) \n",
    "\n",
    "# Convert Julian dates to normal dates in a dataframe \n",
    "merge_df['date_issued'] = (pd.to_datetime((merge_df.issue_date // 1000).astype(str)) + \n",
    "                 pd.to_timedelta(merge_df.issue_date % 1000, unit='D'))\n",
    "\n",
    "# Delete the old column with julian date from which it was converted from\n",
    "merge_df = merge_df.loc[:, ~merge_df.columns.str.contains('^issue_date')]\n",
    "\n",
    "# For loop to convert the military time into regular time and save it into list\n",
    "time_list = []\n",
    "for time in merge_df['issue_time']:\n",
    "    x = datetime.strptime(str(time),'%H%M').strftime('%I:%M %p')\n",
    "    time_list.append(x)\n",
    "\n",
    "merge_df['issue_time'] = time_list\n",
    "\n",
    "# Reset index and delete old index\n",
    "merge_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row observation by condition\n",
    "merge_df= merge_df[merge_df.amount_paid != '($50.00)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object to float\n",
    "merge_df['fine'] = merge_df['fine'].str.replace('$', '').astype(float)\n",
    "merge_df['amount_paid']= merge_df['amount_paid'].str.replace('$', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and delete old index\n",
    "merge_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the final Dataframe to CSV\n",
    "merge_df.to_csv('final_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
    "merge_df['fine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming our primary key is unique\n",
    "merge_df['ticket_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = \"postgres:postgres@localhost:5432/parking_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new data (parking_fines) with select columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_fines_df = merge_df[['ticket_id', 'fine', 'amount_paid', 'date_issued', 'issue_time']].copy()\n",
    "parking_fines_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new data (parking_cars) with select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_cars_df = merge_df[['ticket_id', 'car_make', 'total_tickets']].copy()\n",
    "parking_cars_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new data (parking_location) with select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations_df = merge_df[['ticket_id', 'latitude', 'longitude']].copy()\n",
    "parking_locations_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure the above three tables are created in postgres as well before you start the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas to load csv converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_fines_df.to_sql(name='parking_fines', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_cars_df.to_sql(name='parking_cars', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_locations_df.to_sql(name='parking_location', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data has been added by querying the customer_name table\n",
    "* NOTE: can also check using pgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from parking_fines', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from parking_cars', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from parking_location', con=engine).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
